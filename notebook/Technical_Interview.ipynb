{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### import python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import time\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Financial Statement Crawler\n",
    "Income Statement | Balance Sheet | Financial Ratios\n",
    "#### Statement of one period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def income_statement(year, season):\n",
    "    \n",
    "    # Transform the AD year input to National year system\n",
    "    if year >= 1000:\n",
    "        year -= 1911\n",
    "    \n",
    "    # starting from 102 national year (2013 AD year), IFRSs system is applied\n",
    "    # before then, was GAAP\n",
    "    if year >= 102:\n",
    "        url = 'https://mops.twse.com.tw/mops/web/ajax_t163sb04'\n",
    "    elif year < 102:\n",
    "        url = 'https://mops.twse.com.tw/mops/web/ajax_t51sb13'\n",
    "    else:\n",
    "        print('type does not match')\n",
    "\n",
    "        \n",
    "    r = requests.post(url, \n",
    "                      {'encodeURIComponent':1,\n",
    "                       'step':1,\n",
    "                       'firstin':1,\n",
    "                       'off':1,\n",
    "                       'TYPEK':'sii',\n",
    "                       'year':str(year).zfill(3),\n",
    "                       'season':str(season).zfill(2)})\n",
    "    r.encoding = 'utf8'\n",
    "    \n",
    "    # receive a list of DataFrames\n",
    "    DFs = pd.read_html(r.text)\n",
    "\n",
    "    # data with GAAP system sometimes returns duplicate columns \n",
    "    if year < 102:\n",
    "        for i in DFs:\n",
    "            try:\n",
    "                i.columns = i.columns.droplevel()\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    # the first element is some notification\n",
    "    return DFs[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_sheet(year, season):\n",
    "    \n",
    "    # Transform the AD year input to National year system\n",
    "    if year >= 1000:\n",
    "        year -= 1911\n",
    "    \n",
    "    # starting from 102 national year (2013 AD year), IFRSs system is applied\n",
    "    # before then, was GAAP\n",
    "    if year >= 102:\n",
    "        url = 'https://mops.twse.com.tw/mops/web/ajax_t163sb05'\n",
    "    elif year < 102:\n",
    "        url = 'https://mops.twse.com.tw/mops/web/ajax_t51sb12'\n",
    "    else:\n",
    "        print('type does not match')\n",
    "\n",
    "\n",
    "    r = requests.post(url, \n",
    "                      {'encodeURIComponent':1,\n",
    "                       'step':1,\n",
    "                       'firstin':1,\n",
    "                       'off':1,\n",
    "                       'TYPEK':'sii',\n",
    "                       'year':str(year).zfill(3),\n",
    "                       'season':str(season).zfill(2)})\n",
    "    r.encoding = 'utf8'\n",
    "    \n",
    "    # receive a list of DataFrames\n",
    "    DFs = pd.read_html(r.text)\n",
    "\n",
    "    \n",
    "    if year >= 102:\n",
    "        DFs = DFs[1:]\n",
    "    elif year < 102:\n",
    "        DFs = DFs[1::2]\n",
    "    return DFs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def financial_rate(year):\n",
    "\n",
    "    url = \"https://mops.twse.com.tw/mops/web/ajax_t51sb02\"\n",
    "\n",
    "    # Transform the AD year input to National year system\n",
    "    if year >= 1000:\n",
    "        year -= 1911\n",
    "\n",
    "    # starting from 102 national year (2013 AD year), IFRSs system is applied\n",
    "    # before then, was GAAP\n",
    "    if year>=102:\n",
    "        r = requests.post(url, {\n",
    "            'encodeURIComponent':1,\n",
    "            'step':1,\n",
    "            'run':\"Y\",\n",
    "            'firstin':1,\n",
    "            'off':1,\n",
    "            'TYPEK':'sii',\n",
    "            'year':str(year).zfill(3),\n",
    "            'ifrs':\"Y\",\n",
    "            })\n",
    "    elif year<102:\n",
    "        r = requests.post(url, {\n",
    "            'encodeURIComponent':1,\n",
    "            'step':1,\n",
    "            'firstin':1,\n",
    "            'off':1,\n",
    "            'TYPEK':'sii',\n",
    "            'year':str(year).zfill(3),\n",
    "            })\n",
    "    r.encoding = 'utf8'\n",
    "    \n",
    "    # receive a list of DataFrames\n",
    "    DFs = pd.read_html(r.text)\n",
    "    \n",
    "    # the first element is some notification\n",
    "    return DFs[1:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statement for range of periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def financial_deadline(data, year, season, DFs):\n",
    "    \"\"\"\n",
    "    data are split into different tables based on industries\n",
    "    deadlines for releasing finanical statement for financial industry are different \n",
    "    from other industries.\n",
    "    \"\"\"\n",
    "    if year>=2013:\n",
    "        if season==1:\n",
    "            data[datetime.date(year, 5, 30)] = DFs.pop(-3)\n",
    "            data[datetime.date(year, 5, 15)] = pd.concat(DFs)\n",
    "        elif season == 2:\n",
    "            data[datetime.date(year, 8, 14)] = pd.concat([DFs.pop(2),DFs.pop(-1)])\n",
    "            data[datetime.date(year, 8, 31)] = pd.concat(DFs)\n",
    "        elif season == 3:\n",
    "            data[datetime.date(year, 11, 29)] = DFs.pop(-3)\n",
    "            data[datetime.date(year, 11, 14)] = pd.concat(DFs)\n",
    "        elif season == 4:\n",
    "            data[datetime.date(year+1, 3, 31)] = pd.concat(DFs)\n",
    "    elif year<2013:\n",
    "        if season==1:\n",
    "            data[datetime.date(year, 5, 15)] = pd.concat(DFs)\n",
    "        elif season == 2:\n",
    "            data[datetime.date(year, 8, 31)] = dfs.pop(-4)\n",
    "            data[datetime.date(year, 9, 13)] = pd.concat(DFs)\n",
    "        elif season == 3:\n",
    "            data[datetime.date(year, 11, 14)] = pd.concat(DFs)\n",
    "        elif season == 4:\n",
    "            data[datetime.date(year+1, 3, 31)] = pd.concat(DFs)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def statementCrawler(end_year,end_quater, start_year, statement_type, allow_continuous_fail_count=1):\n",
    "\n",
    "    # init variables\n",
    "    data = {}\n",
    "    fail_count = 0\n",
    "    count_period = 0\n",
    "\n",
    "    n_years = int(start_year)\n",
    "    year = int(end_year)\n",
    "    season = int(end_quater)\n",
    "\n",
    "    while year >= n_years:\n",
    "        print('parsing', str(year)+str(season).zfill(2))\n",
    "        \n",
    "        try:\n",
    "            if statement_type == \"balance_sheet\":\n",
    "                dfs = balance_sheet(year,season)\n",
    "                data = financial_deadline(data, year, season, dfs)\n",
    "            elif statement_type == \"income statement\":\n",
    "                dfs = income_statement(year,season)\n",
    "                data = financial_deadline(data, year, season, dfs)\n",
    "            elif statement_type == \"financial_rate\":\n",
    "                dfs = pd.concat(financial_rate(year))\n",
    "                dfs[\"財報日期\"] = str(year)+\"04\"\n",
    "                data[datetime.date(year+1, 3, 31)] = dfs\n",
    "                season = 1\n",
    "            else:\n",
    "                print(\"invalid statement input\")\n",
    "                break\n",
    "            \n",
    "            print('success!')\n",
    "            count_period +=1\n",
    "            print(count_period)\n",
    "            fail_count = 0\n",
    "            \n",
    "            # only continues if success\n",
    "            if season ==1:\n",
    "                year-=1\n",
    "                season = 4\n",
    "            else:\n",
    "                season -=1\n",
    "\n",
    "        except:\n",
    "            print('Failed')\n",
    "            fail_count += 1\n",
    "            if fail_count == allow_continuous_fail_count:\n",
    "                raise\n",
    "                break\n",
    "\n",
    "        time.sleep(10)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stock Trade Price Crawler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_price(date):\n",
    "    r = requests.post('http://www.twse.com.tw/exchangeReport/MI_INDEX?response=csv&date=' + str(date).replace('-','') + '&type=ALL')\n",
    "    ret = pd.read_csv(StringIO(\"\\n\".join([i.translate({ord(c): None for c in ' '}) \n",
    "                                        for i in r.text.split('\\n') \n",
    "                                        if len(i.split('\",')) == 17 and i[0] != '='])), header=0)\n",
    "    ret = ret.set_index('證券代號')\n",
    "    ret['成交金額'] = ret['成交金額'].str.replace(',','')\n",
    "    ret['成交股數'] = ret['成交股數'].str.replace(',','')\n",
    "    return ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stockpriceCrawler(startDate, endDate=datetime.date.today()):\n",
    "    \n",
    "    # init variables\n",
    "    data = {}\n",
    "    fail_count = 0\n",
    "    count_day = 0\n",
    "    \n",
    "    # avoiding long holidays\n",
    "    allow_continuous_fail_count = 25\n",
    "    \n",
    "    startDate = pd.to_datetime(str(startDate)).date()\n",
    "    \n",
    "    while startDate <= endDate:\n",
    "\n",
    "        print('parsing', endDate)\n",
    "        \n",
    "        try:\n",
    "            data[endDate] = crawl_price(endDate)\n",
    "            print('success!')\n",
    "            count_day +=1\n",
    "            print(count_day)\n",
    "            fail_count = 0\n",
    "        except:\n",
    "            print('fail! check the date is holiday')\n",
    "            fail_count += 1\n",
    "            if fail_count == allow_continuous_fail_count:\n",
    "                raise\n",
    "                break\n",
    "\n",
    "        # backward one day\n",
    "        endDate -= datetime.timedelta(days=1)\n",
    "        time.sleep(15)\n",
    "        \n",
    "    return pd.concat(data).rename_axis([\"日期\",\"證券代號\"]).iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsing 2020-10-18\n",
      "fail! check the date is holiday\n",
      "parsing 2020-10-17\n",
      "fail! check the date is holiday\n",
      "parsing 2020-10-16\n",
      "success!\n",
      "1\n",
      "parsing 2020-10-15\n",
      "success!\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "test1 = stockpriceCrawler(\"2020/10/15\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_bs = pd.concat(bs_df).applymap(lambda x: x if x != '--' else np.nan)\n",
    "all_bs = all_bs[all_bs['公司代號'] != '公司代號']\n",
    "all_bs = all_bs[~all_bs['公司代號'].isnull()]\n",
    "all_bs = all_bs.rename_axis([\"日期\",\"沒用\"]).reset_index().set_index([\"日期\",\"公司名稱\"]).iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_is = pd.concat(is_df).applymap(lambda x: x if x != '--' else np.nan)\n",
    "all_is = all_is[all_is['公司代號'] != '公司代號']\n",
    "all_is = all_is[~all_is['公司代號'].isnull()]\n",
    "all_is = all_is.rename_axis([\"日期\",\"沒用\"]).reset_index().set_index([\"日期\",\"公司名稱\"]).iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_fr = pd.concat(testFR).applymap(lambda x: x if x != '--' else np.nan)\n",
    "all_fr = all_fr[all_fr[('公司代號','公司代號')] != '公司代號']\n",
    "all_fr = all_fr[~all_fr[('公司代號','公司代號')].isnull()]\n",
    "all_fr = all_fr.rename_axis([\"日期\",\"沒用\"]).reset_index().set_index([\"日期\",('公司代號','公司代號')]).iloc[:,1:]\n",
    "all_fr.columns = all_fr.columns.droplevel(0)\n",
    "a = all_fr.columns.to_list()\n",
    "a[-1] = \"財報日期\"\n",
    "all_fr.columns = a\n",
    "all_fr.rename_axis(mapper=[\"日期\",\"公司代號\"],inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column names for Total Asset were not matched\n",
    "# checked the sum data amount of all different  Total Asset which matched the total data amount\n",
    "len(bs_df[\"資產合計\"][~bs_df[\"資產合計\"].isna()])+len(bs_df[\"資產總計\"][~bs_df[\"資產總計\"].isna()])+len(bs_df[\"資產總額\"][~bs_df[\"資產總額\"].isna()])\n",
    "# combined as a new column\n",
    "bs_df[\"總資產\"] = bs_df[\"資產合計\"].fillna(0.0)+bs_df[\"資產總計\"].fillna(0.0)+bs_df[\"資產總額\"].fillna(0.0)\n",
    "\n",
    "# same for the Total Liabilities\n",
    "len(bs_df[\"負債合計\"][~bs_df[\"負債合計\"].isna()])+len(bs_df[\"負債總計\"][~bs_df[\"負債總計\"].isna()])+len(bs_df[\"負債總額\"][~bs_df[\"負債總額\"].isna()])\n",
    "bs_df[\"總負債\"] = bs_df[\"負債合計\"].fillna(0.0)+bs_df[\"負債總計\"].fillna(0.0)+bs_df[\"負債總額\"].fillna(0.0)\n",
    "\n",
    "# same for the Total Equities\n",
    "len(bs_df[\"股東權益合計\"][~bs_df[\"股東權益合計\"].isna()])+len(bs_df[\"股東權益總計\"][~bs_df[\"股東權益總計\"].isna()])+len(bs_df[\"權益合計\"][~bs_df[\"權益合計\"].isna()])+len(bs_df[\"權益總額\"][~bs_df[\"權益總額\"].isna()])+len(bs_df[\"權益總計\"][~bs_df[\"權益總計\"].isna()])\n",
    "bs_df[\"總權益\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(is_df[\"本期淨利（淨損）\"][~is_df[\"本期淨利（淨損）\"].isna()])+len(is_df[\"本期稅後淨利（淨損）\"][~is_df[\"本期稅後淨利（淨損）\"].isna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
